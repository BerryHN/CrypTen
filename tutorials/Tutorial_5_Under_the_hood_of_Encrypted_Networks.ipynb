{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll take a look at how CrypTen performs inference with an encrypted neural network on encrypted data. We'll see how the data remains encrypted through all the operations, and yet is able to obtain accurate results after the computation. \n",
    "\n",
    "\n",
    "### A Simple Linear Layer\n",
    "We'll start by examining how a single Linear layer works in CrypTen. We'll instantiate a Linear layer, encrypt it, and step through some toy data with it. We'll assume Alice has the layer (and the `rank` 0 process) and Bob has the data (and the `rank` 1 process).\n",
    "\n",
    "<small><i>(Technical note: Because Jupyter notebooks run only a single process, we simulate a multi-party world with the @mpc.run_multiprocess decorator.)</i></small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crypten\n",
    "import torch\n",
    "\n",
    "crypten.init() \n",
    "\n",
    "#generate some toy data\n",
    "features = 4\n",
    "examples = 3\n",
    "toy_data = torch.rand(examples, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plaintext Weights: Parameter containing:\n",
      "tensor([[-0.4408, -0.1707,  0.0428, -0.2996],\n",
      "        [-0.0617, -0.3127, -0.4000,  0.1824]], requires_grad=True)\n",
      "Plaintext Bias: Parameter containing:\n",
      "tensor([0.1103, 0.0856], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#Instantiate single Linear layer\n",
    "layer_linear = crypten.nn.Linear(4, 2)\n",
    "\n",
    "#The weights and the bias are initialized to small random values\n",
    "print(\"Plaintext Weights:\", layer_linear._parameters['weight'])\n",
    "print(\"Plaintext Bias:\", layer_linear._parameters['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights Encrypted: True\n",
      "Encrypted data:\n",
      "tensor([[-3529437650444850327, -1384961456004736779, -6929198735789959786,\n",
      "          7050025713128459905],\n",
      "        [-1628411347735222774, -1816930511366182472, -3256300204250465506,\n",
      "          4493608843179679712],\n",
      "        [ 2992598500924676096,  1437511533294625892,    85303661367237954,\n",
      "          2971990899418421934]])\n",
      "Bias Encrypted: True\n",
      "\n",
      "Encrypted Weights:\n",
      "tensor([[-4914577077683699796, -2413527856795080675,  2278954485404849699,\n",
      "          3640852080763557905],\n",
      "        [ 6133062412410498540,   257865353531543276, -4796330528663584032,\n",
      "          8781451695104091633]])\n",
      "Encrypted Bias: tensor([-6544850209041378305, -4417009090129027140])\n",
      "\n",
      "Rank:0 Encrypted result:\n",
      "tensor([[-6544782381304935970, -4417103682313702340],\n",
      "        [-6544979681819059998, -4417126410741752232],\n",
      "        [-6544985919889404546, -4416897672215962903]])\n",
      "Rank:1 Encrypted result:\n",
      "tensor([[6544782381304904285, 4417103682313676136],\n",
      "        [6544979681819037111, 4417126410741712568],\n",
      "        [6544985919889390919, 4416897672215958765]])\n",
      "\n",
      "\n",
      "Decrypted result:\n",
      " tensor([[-0.4835, -0.3998],\n",
      "        [-0.3492, -0.6052],\n",
      "        [-0.2079, -0.0631]])\n"
     ]
    }
   ],
   "source": [
    "import crypten.mpc as mpc\n",
    "import crypten.communicator as comm\n",
    "\n",
    "@mpc.run_multiprocess(world_size=2)\n",
    "def forward_single_encrypted_layer():\n",
    "    rank = comm.get().get_rank()\n",
    "    \n",
    "    #Loading the layer\n",
    "    if rank == 0:\n",
    "        #Alice loads the layer\n",
    "        layer_enc = layer_linear\n",
    "    else:\n",
    "        #Bob loads a dummy layer\n",
    "        layer_enc = crypten.nn.Linear(4, 2)\n",
    "        \n",
    "    #Loading the toy data\n",
    "    if rank == 1:\n",
    "        #Bob loads the toy data\n",
    "        toy_data_upd = toy_data\n",
    "    else:\n",
    "        #Alice loads dummy data\n",
    "        toy_data_upd = torch.empty(toy_data.size())\n",
    "    \n",
    "    #Encrypting the linear layer and the data\n",
    "    layer_enc.encrypt(src=0) #note src=0!\n",
    "    toy_data_enc = crypten.cryptensor(toy_data_upd, src=1) #note src=1!\n",
    "    \n",
    "    #Let's now examine the shares inside the encrypted toy data\n",
    "    #We only print rank 0 information for readability\n",
    "    if rank == 1:\n",
    "        print(\"Encrypted data:\\n{}\\n\".format(toy_data_enc.share))\n",
    "\n",
    "    #Let's also examine the weights and the bias of the linear layer again\n",
    "    #We only print rank 0 information for readability\n",
    "    if rank == 0:\n",
    "        #First, we'll see that weights and bias have become encrypted tensors\n",
    "        print(\"Weights Encrypted: {}\".format(crypten.is_encrypted_tensor(layer_enc._parameters['weight'])))\n",
    "        print(\"Bias Encrypted: {}\".format(crypten.is_encrypted_tensor(layer_enc._parameters['bias'])))\n",
    "\n",
    "        #Now let's look at the tensor values\n",
    "        print(\"Encrypted Weights:\\n{}\".format(layer_enc._parameters['weight'].share))\n",
    "        print(\"Encrypted Bias: {}\".format(layer_enc._parameters['bias'].share))\n",
    "        print()\n",
    "\n",
    "    #apply the encrypted layer: encrypted linear transformation \n",
    "    result_enc = layer_enc.forward(toy_data_enc)\n",
    "    \n",
    "    #we'll print the resulting shares of both parties\n",
    "    print(\"Rank:{} Encrypted result:\\n{}\\n\".format(rank, result_enc.share))\n",
    "    \n",
    "    #decrypt the result:\n",
    "    result_plaintext = result_enc.get_plain_text()\n",
    "    #we'll print only rank 0 values for readability\n",
    "    if rank == 0:\n",
    "        print(\"Decrypted result:\\n\", result_plaintext)\n",
    "        \n",
    "z = forward_single_encrypted_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the application of the encrypted linear layer on the encrypted data produces an encrypted result, which we can then decrypt to get the values in plaintext.\n",
    "\n",
    "Let's look at a second linear transformation, to give a flavor of how accuracy is preserved even when the data and the layer are encrypted. We'll look at a uniform scaling transformation, in which all tensor elements are multiplied by the same scalar factor. Again, we'll assume Alice has the layer and the `rank` 0 process, and Bob has the data and the `rank` 1 process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encrypted data:\n",
      "tensor([[-5274762416354429527,  3044720233427754283, -8084390380562988153],\n",
      "        [ 4844508570170404561,  -739434560346899506,  9015698232244756031]])\n",
      "Encrypted Weights:\n",
      "tensor([[  883198664398464434,  1303801953729869595,  9032040305735239635],\n",
      "        [  607235406868532498,  3299040990922350992,   538347453982252238],\n",
      "        [ 2915046868926881237,  1765978872310897706, -2863619390377126375]])\n",
      "\n",
      "Encrypted Bias:\n",
      "tensor([-7901549011774995946,  -937043077034743511, -7669741716401089189])\n",
      "Rank 0 Encrypted result:\n",
      " tensor([[-7901487379265356323,  -937179007628379228, -7669839616455256762],\n",
      "        [-7901657443855509253,  -937015236487772829, -7669760671194908171]])\n",
      "Rank 1 Encrypted result:\n",
      " tensor([[7901487379265684003,  937179007628706908, 7669839616455584442],\n",
      "        [7901657443855836933,  937015236488100509, 7669760671195235851]])\n",
      "\n",
      "\n",
      "Plaintext result:\n",
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "#Initialize a linear layer with random weights\n",
    "layer_scale = crypten.nn.Linear(3, 3)\n",
    "\n",
    "#Construct a uniform scaling matrix: we'll scale by factor 5\n",
    "factor = 5\n",
    "layer_scale._parameters['weight'] = torch.eye(3)*factor\n",
    "layer_scale._parameters['bias'] = torch.zeros_like(layer_scale._parameters['bias'])\n",
    "\n",
    " #Construct some toy data\n",
    "toy_data = torch.ones(2, 3)\n",
    "\n",
    "@mpc.run_multiprocess(world_size=2)\n",
    "def forward_scaling_layer():\n",
    "    rank = comm.get().get_rank()\n",
    "    \n",
    "    if rank == 0:\n",
    "        #Alice gets the scaling layer\n",
    "        layer_enc = layer_scale\n",
    "    else:\n",
    "        #Bob gets a dummy layer\n",
    "        layer_enc = layer_scale\n",
    "    \n",
    "    if rank == 1:\n",
    "        #Bob gets the toy data\n",
    "        data = toy_data\n",
    "    else:\n",
    "        #Alice gets dummy data\n",
    "        data = torch.empty(toy_data.size())\n",
    "    \n",
    "    \n",
    "    #Encrypt the layer\n",
    "    layer_enc.encrypt(src=0)\n",
    "    #Encrypt the toy data\n",
    "    toy_data_enc = crypten.cryptensor(data, src=1)\n",
    "    \n",
    "    #Let's first look at the encrypted data\n",
    "    #We'll restrict printing to rank 1 for readability\n",
    "    if rank == 1:\n",
    "        print(\"Encrypted data:\\n{}\\n\".format(toy_data_enc.share))\n",
    "        \n",
    "    #Let's now look inside the encrypted layer\n",
    "    #We'll restrict printing to rank 0 for readability\n",
    "    if rank == 0:\n",
    "        print(\"Encrypted Weights:\\n{}\".format(layer_enc._parameters['weight'].share))\n",
    "        print(\"Encrypted Bias:\\n{}\".format(layer_enc._parameters['bias'].share))\n",
    "\n",
    "    #Apply the encrypted scaling transformation\n",
    "    result_enc = layer_enc.forward(toy_data_enc)\n",
    "    \n",
    "    #Let's examine the encrypted results\n",
    "    print(\"Rank {} Encrypted result:\\n {}\\n\".format(rank, result_enc.share))\n",
    "\n",
    "    #Decrypt the result:\n",
    "    result_plaintext = result_enc.get_plain_text()\n",
    "    #We'll print only rank 0 for readability\n",
    "    if rank == 0:\n",
    "        print(\"Plaintext result:\\n{}\".format(result_plaintext))\n",
    "        \n",
    "z = forward_scaling_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting plaintext tensor is correctly scaled, even though we applied the encrypted transformation on the encrypted input! \n",
    "\n",
    "### Multi-layer Neural Networks\n",
    "Let's now look at how the encrypted input moves through an encrypted multi-layer neural network. \n",
    "\n",
    "For ease of explanation, we'll first step through a network with only two linear layers and ReLU activations. Again, we'll assume Alice has a network and Bob has some data, and they wish to run encrypted inference. \n",
    "\n",
    "To simulate this, we'll once again generate some toy data and train Alice's network on it. Then we'll encrypt Alice's network, Bob's data, and step through every layer in the network with the encrypted data. Through this, we'll see how the computations get applied although the network and the data are encrypted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll generate some random data for illustration purposes.\n",
    "features = 50\n",
    "examples = 100\n",
    "data = torch.randn(examples, features)\n",
    "w_true = torch.randn(1, features)\n",
    "b_true = torch.randn(1)\n",
    "y = w_true.matmul(data.t()) + b_true\n",
    "y = y.sign()\n",
    "\n",
    "#change labels to format needed by training\n",
    "y2 = torch.where(y==-1, torch.zeros(y.size()), y)\n",
    "y2 = y2.squeeze().long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Alice and Bob's data\n",
    "data_alice = data[:90,:]\n",
    "data_bob = data[90:,:]\n",
    "\n",
    "label_alice = y2[:90]\n",
    "label_bob = y2[90:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Loss: 0.07619381695985794\n",
      "Epoch 199 Loss: 0.01975707896053791\n",
      "Epoch 299 Loss: 0.009856403805315495\n",
      "Epoch 399 Loss: 0.006247421260923147\n",
      "Epoch 499 Loss: 0.0044706217013299465\n"
     ]
    }
   ],
   "source": [
    "#Alice creates a very simple one layer network\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Define Alice's network\n",
    "class AliceNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AliceNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(50, 20)\n",
    "        self.fc2 = nn.Linear(20, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = AliceNet()\n",
    "\n",
    "#Train Alice's network\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for i in range(500):  \n",
    "    #forward pass: compute prediction\n",
    "    output = model(data_alice)\n",
    "    \n",
    "    #compute and print loss\n",
    "    loss = criterion(output, label_alice)\n",
    "    if i % 100 == 99:\n",
    "        print(\"Epoch\", i, \"Loss:\", loss.item())\n",
    "    \n",
    "    #zero gradients for learnable parameters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #backward pass: compute gradient with respect to model parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    #update model parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at what happens when we encrypt the network that Alice has trained. (For readability, we illustrate this in a world with only Alice, and do not simulate multi-party world or include the code for Bob's process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 5 \tModule: <crypten.nn.module.Linear object at 0x7fe0d8d7eac8>\n",
      "Name: 6 \tModule: <crypten.nn.module.ReLU object at 0x7fe05b8d55c0>\n",
      "Name: output \tModule: <crypten.nn.module.Linear object at 0x7fe05b8d55f8>\n"
     ]
    }
   ],
   "source": [
    "#Let's look at what happens when a neural network gets encrypted\n",
    "\n",
    "#Create dummy input of the correct input shape for the model\n",
    "dummy_input = torch.empty((1, 50))\n",
    "\n",
    "#Encrypt the network\n",
    "private_model = crypten.nn.from_pytorch(model, dummy_input)\n",
    "private_model.encrypt(src=0)\n",
    "\n",
    "#Let's look at the structure of the encrypted network\n",
    "for name, curr_module in private_model._modules.items():\n",
    "    print(\"Name:\", name, \"\\tModule:\", curr_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the encrypted networks has 3 modules, named '5', '6' and 'output', denoting the first Linear layer, the ReLU activation, and the second Linear layer respectively. These modules are encrypted just as the layers in the previous section were. \n",
    "\n",
    "Now let's encrypt Bob's data, and step it through each encrypted module. For readability, we will use only 3 examples from Bob's data to illustrate the inference. Note how Bob's data remains encrypted after each individual layer's computation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 0 First Linear Layer: Output Encrypted: True\n",
      "Rank: 1 First Linear Layer: Output Encrypted: True\n",
      "\n",
      "\n",
      "Rank: 1 Shares after First Linear Layer:tensor([[-7903544318455955739,  7617702702855408976, -7052570795069168591,\n",
      "          1727656015794399854,  5159531949446533624,  7228455143419277603,\n",
      "          5785954513225743731, -2125448590957328485,  4798305163009888226,\n",
      "          4469307498453606896,   611300775826289751,  6608534528173682827,\n",
      "          1842994992776239801,  5773411982157767484,  2309732521878634774,\n",
      "         -4195880852394788682,  7373027241720826123, -4490330287736089950,\n",
      "          3025915678758970324, -9115159967454467117],\n",
      "        [-7903493116439411434,  7617774502227285949, -7052422176647185589,\n",
      "          1727779565068718304,  5159715460184703137,  7228591328842862996,\n",
      "          5785957688218679039, -2125412666572421222,  4798439219769935731,\n",
      "          4469312955166640597,   611429997679430363,  6608583579100475340,\n",
      "          1842813703491054238,  5773363991466985580,  2309627603814102828,\n",
      "         -4195896354750479854,  7372917306192772815, -4490298918434707451,\n",
      "          3025909422597352186, -9115280874074317663],\n",
      "        [-7903378999280145524,  7617728063158787098, -7052432663887937697,\n",
      "          1727547420073737493,  5159687765023711584,  7228582863193008911,\n",
      "          5785941938983292457, -2125553455335022657,  4798351601907012246,\n",
      "          4469413671948023881,   611436795405200356,  6608495411804238089,\n",
      "          1842871517310448419,  5773371550936733164,  2309525748128894218,\n",
      "         -4195777661368084165,  7372878760028388638, -4490365014664066674,\n",
      "          3025845341066749923, -9115384662981870811]])\n",
      "Rank: 0 Shares after First Linear Layer:tensor([[ 7903544318455925243, -7617702702855423692,  7052570795069097492,\n",
      "         -1727656015794321805, -5159531949446494038, -7228455143419129968,\n",
      "         -5785954513225741114,  2125448590957316980, -4798305163009896191,\n",
      "         -4469307498453603650,  -611300775826357316, -6608534528173567787,\n",
      "         -1842994992776229856, -5773411982157853447, -2309732521878652977,\n",
      "          4195880852394748867, -7373027241720839439,  4490330287736118582,\n",
      "         -3025915678758927596,  9115159967454527446],\n",
      "        [ 7903493116439513131, -7617774502227330227,  7052422176647203276,\n",
      "         -1727779565068614917, -5159715460184614524, -7228591328842837149,\n",
      "         -5785957688218636111,  2125412666572382736, -4798439219769925565,\n",
      "         -4469312955166635467,  -611429997679525974, -6608583579100546767,\n",
      "         -1842813703490999307, -5773363991466901598, -2309627603814106413,\n",
      "          4195896354750480033, -7372917306192831188,  4490298918434654253,\n",
      "         -3025909422597381902,  9115280874074231739],\n",
      "        [ 7903378999280210140, -7617728063158812139,  7052432663887956476,\n",
      "         -1727547420073776896, -5159687765023712963, -7228582863192978910,\n",
      "         -5785941938983319320,  2125553455335000394, -4798351601907012759,\n",
      "         -4469413671948059038,  -611436795405235765, -6608495411804302818,\n",
      "         -1842871517310443233, -5773371550936782278, -2309525748128852432,\n",
      "          4195777661368143456, -7372878760028371555,  4490365014664006997,\n",
      "         -3025845341066813577,  9115384662981929953]])\n",
      "\n",
      "\n",
      "Rank: 1 ReLU:\n",
      " Output Encrypted: True\n",
      "Rank: 0 ReLU:\n",
      " Output Encrypted: True\n",
      "\n",
      "\n",
      "Rank: 1 Shares after ReLU: tensor([[   8678703222036, -102606185585951,  135666547412417,    1662422835398,\n",
      "           73713235862078,   -8666410607035,   69080137493371,   16428017746506,\n",
      "          -25469729656161,  138661432460779,   71974043094508,  -27742684509256,\n",
      "            8689379854013,   31146444670769,  134977618101164,   46204901607517,\n",
      "          131667050153438,   31458509535542,    1207453039269,   30138978530529],\n",
      "        [ -37418332405343,   43870589223038,     919535247119,   -4380628569870,\n",
      "          -86698290958473,   25440656454131,  105140464696428,  -34531593933717,\n",
      "         -118637770087552,  140698137836540,   12126233936916,   71576757718912,\n",
      "         -128964394077704,  -77739048925757,  -78963747972159,   47030483322211,\n",
      "          114555666547129,  -75047001914850,  -48961485666793,  -91057145562914],\n",
      "        [  63779773704654,  -45790888534995,  -97386101037135,  -28444576714315,\n",
      "          137389098390943,   72580136707032,   71843814002561, -108008642344419,\n",
      "          -93349197568700,  -21462840554375, -119473753147752,  123719202304117,\n",
      "          126415794402367,   79385081899881,   30810150535213,  -36238496630527,\n",
      "           60242865095904,   65029162281604,  -16554476710271,   71641776431180]])\n",
      "Rank: 0 Shares after ReLU: tensor([[  -8678703222036,  102606185585951, -135666547412417,   -1662422757349,\n",
      "          -73713235822492,    8666410754670,  -69080137490754,  -16428017746506,\n",
      "           25469729656161, -138661432457533,  -71974043094508,   27742684624296,\n",
      "           -8689379844068,  -31146444670769, -134977618101164,  -46204901607517,\n",
      "         -131667050153438,  -31458509506910,   -1207452996541,  -30138978470200],\n",
      "        [  37418332507040,  -43870589223038,    -919535229432,    4380628673257,\n",
      "           86698291047086,  -25440656428284, -105140464653500,   34531593933717,\n",
      "          118637770097718, -140698137831410,  -12126233936916,  -71576757718912,\n",
      "          128964394132635,   77739049009739,   78963747972159,  -47030483322032,\n",
      "         -114555666547129,   75047001914850,   48961485666793,   91057145562914],\n",
      "        [ -63779773640038,   45790888534995,   97386101055914,   28444576714315,\n",
      "         -137389098390943,  -72580136677031,  -71843814002561,  108008642344419,\n",
      "           93349197568700,   21462840554375,  119473753147752, -123719202304117,\n",
      "         -126415794397181,  -79385081899881,  -30810150493427,   36238496689818,\n",
      "          -60242865078821,  -65029162281604,   16554476710271,  -71641776372038]])\n",
      "\n",
      "\n",
      "Rank: 0 Second Linear layer:\n",
      " Output Encrypted: True\n",
      "Rank: 1 Second Linear layer:\n",
      " Output Encrypted: True\n",
      "\n",
      "\n",
      "Rank: 0 Shares after Second Linear layer:tensor([[-5052717557604664261,  8207605985068281711],\n",
      "        [-5052548276176453288,  8207733370487521166],\n",
      "        [-5052698991949946339,  8207692043793330398]])\n",
      "Rank: 1 Shares after Second Linear layer:tensor([[ 5052717557604563328, -8207605985068154311],\n",
      "        [ 5052548276176542614, -8207733370487574901],\n",
      "        [ 5052698991950049562, -8207692043793436513]])\n",
      "\n",
      "\n",
      "Decrypted output:\n",
      " Output Encrypted: False\n",
      "Tensors:\n",
      " tensor([[-1.5401,  1.9440],\n",
      "        [ 1.3630, -0.8199],\n",
      "        [ 1.5751, -1.6192]])\n"
     ]
    }
   ],
   "source": [
    "#Select only the first three examples of Bob's data for readability\n",
    "data = data_bob[:3,:]\n",
    "\n",
    "#Create dummy input of the correct input shape for the model\n",
    "dummy_input = torch.empty((1, 50))\n",
    "\n",
    "@mpc.run_multiprocess(world_size=2)\n",
    "def step_through_two_layers():\n",
    "    \n",
    "    rank = comm.get().get_rank()\n",
    "    \n",
    "    if rank == 0:\n",
    "        #Alice gets the trained network\n",
    "        model_upd = model\n",
    "    else:\n",
    "        #Bob gets a dummy layer\n",
    "        model_upd = AliceNet()\n",
    "        \n",
    "    if rank == 1:\n",
    "        #Bob gets the trained data\n",
    "        data_upd = data\n",
    "    else:\n",
    "        #Alice gets the dummy layer\n",
    "        data_upd = torch.empty(data.size())\n",
    "\n",
    "    #Encrypt the network\n",
    "    private_model = crypten.nn.from_pytorch(model_upd, dummy_input)\n",
    "    private_model.encrypt(src=0)\n",
    "\n",
    "    #Encrypt the data\n",
    "    data_enc = crypten.cryptensor(data, src=1)\n",
    "\n",
    "    #forward through the first layer\n",
    "    out_enc = private_model._modules['5'].forward(data_enc)\n",
    "    print(\"Rank: {} First Linear Layer: Output Encrypted: {}\\n\".format(rank, crypten.is_encrypted_tensor(out_enc)))\n",
    "    print(\"Rank: {} Shares after First Linear Layer:{}\\n\".format(rank, out_enc.share))\n",
    "\n",
    "    #apply ReLU activation\n",
    "    out_enc = private_model._modules['6'].forward(out_enc)\n",
    "    print(\"Rank: {} ReLU:\\n Output Encrypted: {}\\n\".format(rank, crypten.is_encrypted_tensor(out_enc)))\n",
    "    print(\"Rank: {} Shares after ReLU: {}\\n\".format(rank, out_enc.share))\n",
    "\n",
    "    #forward through the second Linear layer\n",
    "    out_enc = private_model._modules['output'].forward(out_enc)\n",
    "    print(\"Rank: {} Second Linear layer:\\n Output Encrypted: {}\\n\".format(rank, crypten.is_encrypted_tensor(out_enc))), \n",
    "    print(\"Rank: {} Shares after Second Linear layer:{}\\n\".format(rank, out_enc.share))\n",
    "\n",
    "    #decrypt the output\n",
    "    out_dec = out_enc.get_plain_text()\n",
    "    #For readability, only print the rank 0 output (identical for rank 1)\n",
    "    if rank == 0:\n",
    "        print(\"Decrypted output:\\n Output Encrypted:\", crypten.is_encrypted_tensor(out_dec))\n",
    "        print(\"Tensors:\\n\", out_dec)\n",
    "    \n",
    "z = step_through_two_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we emphasize that the output of each layer is an encrypted tensor. Only after the final call to `get_plain_text` do we get the plaintext tensor.\n",
    "\n",
    "We have used a simple two-layer network in our example, but the same ideas apply to more complex networks and operations. However, in more complex networks, there may not always be a one-to-one mapping between the PyTorch layers and the CrypTen layers. As an example, we'll take a typical network used to classify digits in MNIST data, and look at what happens to its structure when encrypted. (As we only wish to illustrate the structural changes in layers, we will not train this network on data; we will just use it with its randomly initialized weights). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 24 \tModule: <crypten.nn.module.Conv2d object at 0x7fe0402f6908>\n",
      "Name: 25 \tModule: <crypten.nn.module._BatchNorm object at 0x7fe0402f6358>\n",
      "Name: 26 \tModule: <crypten.nn.module.ReLU object at 0x7fe0402f67b8>\n",
      "Name: 27 \tModule: <crypten.nn.module._ConstantPad object at 0x7fe0402f6048>\n",
      "Name: 28 \tModule: <crypten.nn.module.AvgPool2d object at 0x7fe0402f62e8>\n",
      "Name: 29 \tModule: <crypten.nn.module.Conv2d object at 0x7fe0402f6860>\n",
      "Name: 30 \tModule: <crypten.nn.module._BatchNorm object at 0x7fe0402f6cc0>\n",
      "Name: 31 \tModule: <crypten.nn.module.ReLU object at 0x7fe0402f6a58>\n",
      "Name: 32 \tModule: <crypten.nn.module._ConstantPad object at 0x7fe0402f6be0>\n",
      "Name: 33 \tModule: <crypten.nn.module.AvgPool2d object at 0x7fe0402f6d68>\n",
      "Name: 34 \tModule: <crypten.nn.module.Constant object at 0x7fe0402e6358>\n",
      "Name: 35 \tModule: <crypten.nn.module.Shape object at 0x7fe0402e60f0>\n",
      "Name: 36 \tModule: <crypten.nn.module.Gather object at 0x7fe0402e6198>\n",
      "Name: 37 \tModule: <crypten.nn.module.Constant object at 0x7fe0402e63c8>\n",
      "Name: 38 \tModule: <crypten.nn.module.Unsqueeze object at 0x7fe0402e6550>\n",
      "Name: 39 \tModule: <crypten.nn.module.Unsqueeze object at 0x7fe0402e66a0>\n",
      "Name: 40 \tModule: <crypten.nn.module.Concat object at 0x7fe0402e67f0>\n",
      "Name: 41 \tModule: <crypten.nn.module.Reshape object at 0x7fe0402e6940>\n",
      "Name: 42 \tModule: <crypten.nn.module.Linear object at 0x7fe0402e6b00>\n",
      "Name: 43 \tModule: <crypten.nn.module.Unsqueeze object at 0x7fe0402e6c50>\n",
      "Name: 44 \tModule: <crypten.nn.module._BatchNorm object at 0x7fe0402e6d30>\n",
      "Name: 45 \tModule: <crypten.nn.module.Squeeze object at 0x7fe0402e6e80>\n",
      "Name: 46 \tModule: <crypten.nn.module.ReLU object at 0x7fe0402e6f28>\n",
      "Name: output \tModule: <crypten.nn.module.Linear object at 0x7fe0402f9128>\n"
     ]
    }
   ],
   "source": [
    "#Define Alice's network\n",
    "class AliceNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AliceNet2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=5, padding=0)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(16)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(100)\n",
    " \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = F.relu(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = self.conv2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = F.relu(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.batchnorm3(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = AliceNet2()\n",
    "\n",
    "#Let's encrypt the more complex network. \n",
    "#Create dummy input of the correct input shape for the model\n",
    "dummy_input = torch.empty((1, 1, 28, 28))\n",
    "\n",
    "#Encrypt the network\n",
    "private_model = crypten.nn.from_pytorch(model, dummy_input)\n",
    "private_model.encrypt(src=0)\n",
    "\n",
    "#Let's look at the structure of the encrypted network\n",
    "for name, curr_module in private_model._modules.items():\n",
    "    print(\"Name:\", name, \"\\tModule:\", curr_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the CrypTen network has split the PyTorch network into several additional layers. Each PyTorch operation may correspond to one or more operations in CrypTen. Nevertheless, the same ideas apply when forwarding the data through the CrypTen equivalent of each PyTorch operation. \n",
    "\n",
    "For additional details, please see the CrypTen whitepaper. "
   ]
  }
 ],
 "metadata": {
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "disseminate_notebook_id": {
   "notebook_id": "511641209674539"
  },
  "disseminate_notebook_info": {
   "bento_version": "20190826-030256",
   "description": "",
   "hide_code": false,
   "hipster_group": "",
   "kernel_build_info": {
    "error": "The file located at '/data/users/shobha/fbsource/fbcode/bento/kernels/local/cryptenk/TARGETS' could not be found."
   },
   "no_uii": true,
   "notebook_number": "139530",
   "others_can_edit": true,
   "reviewers": "",
   "revision_id": "417315762230172",
   "tags": "",
   "tasks": "",
   "title": "Tutorial 5 -- Under the hood of Encrypted Networks"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
